{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eosC0fERt6DY"
   },
   "source": [
    "# Gradient Episodic Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2uLpHMYD4iT-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import pyfiles.GEM as GEM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m0NTE-5OtXG-"
   },
   "source": [
    "### Define P-MNIST data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZlE3KQNSstue"
   },
   "outputs": [],
   "source": [
    "class PermutedMNISTDataLoader(torchvision.datasets.MNIST):\n",
    "    def __init__(self, source='data/mnist_data', train = True, shuffle_seed = None):\n",
    "        super(PermutedMNISTDataLoader, self).__init__(source, train, download=True)\n",
    "        \n",
    "        self.train = train\n",
    "        self.num_data = 0\n",
    "        \n",
    "        if self.train:\n",
    "            self.permuted_train_data = torch.stack(\n",
    "                [img.type(dtype=torch.float32).view(-1)[shuffle_seed] / 255.0\n",
    "                    for img in self.train_data])\n",
    "            self.num_data = self.permuted_train_data.shape[0]\n",
    "            \n",
    "        else:\n",
    "            self.permuted_test_data = torch.stack(\n",
    "                [img.type(dtype=torch.float32).view(-1)[shuffle_seed] / 255.0\n",
    "                    for img in self.test_data])\n",
    "            self.num_data = self.permuted_test_data.shape[0]\n",
    "            \n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        if self.train:\n",
    "            input, label = self.permuted_train_data[index], self.train_labels[index]\n",
    "        else:\n",
    "            input, label = self.permuted_test_data[index], self.test_labels[index]\n",
    "        \n",
    "        return input, label\n",
    "\n",
    "    \n",
    "    def getNumData(self):\n",
    "        return self.num_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iqgMTMVctR4K"
   },
   "source": [
    "### Set hyperparameters & get permuted MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "learning_rate = 1e-2\n",
    "num_task = 10\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "cuda_available = False\n",
    "if torch.cuda.is_available():\n",
    "    cuda_available = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M5l-BVows2rQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/mnist_data/PermutedMNISTDataLoader/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9920512it [00:02, 3314130.95it/s]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/mnist_data/PermutedMNISTDataLoader/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/mnist_data/PermutedMNISTDataLoader/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32768it [00:00, 48141.24it/s]                           \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/mnist_data/PermutedMNISTDataLoader/raw/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/mnist_data/PermutedMNISTDataLoader/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1654784it [00:01, 901746.75it/s]                            \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/mnist_data/PermutedMNISTDataLoader/raw/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/mnist_data/PermutedMNISTDataLoader/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8192it [00:00, 18292.85it/s]            \n",
      "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:53: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/mnist_data/PermutedMNISTDataLoader/raw/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:58: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n"
     ]
    }
   ],
   "source": [
    "def permute_mnist():\n",
    "    train_loader = {}\n",
    "    test_loader = {}\n",
    "    \n",
    "    train_data_num = 0\n",
    "    test_data_num = 0\n",
    "    \n",
    "    for i in range(num_task):\n",
    "        shuffle_seed = np.arange(28*28)\n",
    "        np.random.shuffle(shuffle_seed)\n",
    "        \n",
    "        train_PMNIST_DataLoader = PermutedMNISTDataLoader(train=True, shuffle_seed=shuffle_seed)\n",
    "        test_PMNIST_DataLoader = PermutedMNISTDataLoader(train=False, shuffle_seed=shuffle_seed)\n",
    "        \n",
    "        train_data_num += train_PMNIST_DataLoader.getNumData()\n",
    "        test_data_num += test_PMNIST_DataLoader.getNumData()\n",
    "        \n",
    "        train_loader[i] = torch.utils.data.DataLoader(\n",
    "                train_PMNIST_DataLoader,\n",
    "                batch_size=batch_size)\n",
    "        \n",
    "        test_loader[i] = torch.utils.data.DataLoader(\n",
    "                test_PMNIST_DataLoader,\n",
    "                batch_size=batch_size)\n",
    "    \n",
    "    return train_loader, test_loader, int(train_data_num/num_task), int(test_data_num/num_task)\n",
    "\n",
    "train_loader, test_loader, train_data_num, test_data_num = permute_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xxLFhyw9tPn6"
   },
   "source": [
    "### Define Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5xq7gI87s7-m"
   },
   "outputs": [],
   "source": [
    "class NeuralNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        # Always start with inheriting torch.nn.Module\n",
    "        # Ancestor class of all Neural Net module\n",
    "        super(NeuralNet, self).__init__()\n",
    "        # Linear: linear transformation\n",
    "        fc1 = torch.nn.Linear(28*28, 100)\n",
    "        fc2 = torch.nn.Linear(100, 100)\n",
    "        fc3 = torch.nn.Linear(100, 100)\n",
    "  \n",
    "        \n",
    "        self.fc_module = torch.nn.Sequential(\n",
    "            fc1,\n",
    "            torch.nn.ReLU(),\n",
    "            fc2,\n",
    "            torch.nn.ReLU(),\n",
    "            fc3\n",
    "        )\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            self.fc_module = self.fc_module.cuda()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc_module(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ukUD3JrixCiK"
   },
   "source": [
    "### Continual Learnig with GEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z0kcpGclwi6_",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[78400, 100, 10000, 100, 10000, 100]\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.01\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "CrossEntropyLoss()\n",
      "Memory size:  100\n",
      "[1\t100] AVG. loss: 0.461\n",
      "\n",
      "[1\t200] AVG. loss: 0.225\n",
      "\n",
      "[1\t300] AVG. loss: 0.146\n",
      "\n",
      "[1\t400] AVG. loss: 0.102\n",
      "\n",
      "[1\t500] AVG. loss: 0.073\n",
      "\n",
      "[1\t600] AVG. loss: 0.051\n",
      "\n",
      "[1\t700] AVG. loss: 0.036\n",
      "\n",
      "[1\t800] AVG. loss: 0.026\n",
      "\n",
      "[1\t900] AVG. loss: 0.019\n",
      "\n",
      "tensor([[82.4700,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000]], device='cuda:0')\n",
      "[2\t100] AVG. loss: 0.466\n",
      "\n",
      "[2\t200] AVG. loss: 0.232\n",
      "\n",
      "[2\t300] AVG. loss: 0.154\n",
      "\n",
      "[2\t400] AVG. loss: 0.115\n",
      "\n",
      "[2\t500] AVG. loss: 0.092\n",
      "\n",
      "[2\t600] AVG. loss: 0.077\n",
      "\n",
      "[2\t700] AVG. loss: 0.066\n",
      "\n",
      "[2\t800] AVG. loss: 0.058\n",
      "\n",
      "[2\t900] AVG. loss: 0.051\n",
      "\n",
      "tensor([[82.4700,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [59.0100,  9.7200,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000]], device='cuda:0')\n",
      "[3\t100] AVG. loss: 0.465\n",
      "\n",
      "[3\t200] AVG. loss: 0.231\n",
      "\n",
      "[3\t300] AVG. loss: 0.154\n",
      "\n",
      "[3\t400] AVG. loss: 0.115\n",
      "\n",
      "[3\t500] AVG. loss: 0.092\n",
      "\n",
      "[3\t600] AVG. loss: 0.077\n",
      "\n",
      "[3\t700] AVG. loss: 0.066\n",
      "\n",
      "[3\t800] AVG. loss: 0.058\n",
      "\n",
      "[3\t900] AVG. loss: 0.051\n",
      "\n",
      "tensor([[82.4700,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [59.0100,  9.7200,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [52.6900,  9.3700, 14.0600,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000]], device='cuda:0')\n",
      "[4\t100] AVG. loss: 0.465\n",
      "\n",
      "[4\t200] AVG. loss: 0.231\n",
      "\n",
      "[4\t300] AVG. loss: 0.154\n",
      "\n",
      "[4\t400] AVG. loss: 0.115\n",
      "\n",
      "[4\t500] AVG. loss: 0.092\n",
      "\n",
      "[4\t600] AVG. loss: 0.077\n",
      "\n",
      "[4\t700] AVG. loss: 0.066\n",
      "\n",
      "[4\t800] AVG. loss: 0.058\n",
      "\n",
      "[4\t900] AVG. loss: 0.051\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net = NeuralNet()\n",
    "optim = torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
    "memsize_list = [100, 300, 1000, 3000, 10000]\n",
    "#logfile_name = \"logfile_training_gem_%d_%d_%d_%d_%d.txt\" % (dt.year, dt.month, dt.day, dt.hour, dt.minute)\n",
    "\n",
    "for mem_size in memsize_list:\n",
    "    gem = GEM.GEMLearning(net = net,\n",
    "                          tasks = num_task,\n",
    "                          optim = optim,\n",
    "                          criterion = criterion,\n",
    "                          mem_size = mem_size,\n",
    "                          #num_input = ,\n",
    "                          traindata_len = train_data_num,\n",
    "                          testdata_len = test_data_num,\n",
    "                          batch_size = batch_size)\n",
    "    \n",
    "    for i in range(num_task):\n",
    "        gem.train(train_loader[i], i)\n",
    "        \n",
    "        for j in range(i+1):\n",
    "            gem.eval(test_loader[j], j)\n",
    "            \n",
    "        print(gem.R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MNIST_GEM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
